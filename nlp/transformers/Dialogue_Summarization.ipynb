{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Dialogue Summarization"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "112f6a8c7922410e8c72c35f4502a5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c15ec4f9e29f4835b085bb0223b5ebfc",
              "IPY_MODEL_da7601058b3d40f6b9cbbbfddaeeaa5c",
              "IPY_MODEL_99b892d921d8408a8d6d795d706a55a0"
            ],
            "layout": "IPY_MODEL_379f5f2448d84d709169c0a516170329"
          }
        },
        "c15ec4f9e29f4835b085bb0223b5ebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a4b53c890b4180ac72b2cffd8f47e2",
            "placeholder": "​",
            "style": "IPY_MODEL_538d907a219b42ca845805d65b762b2f",
            "value": "Map: 100%"
          }
        },
        "da7601058b3d40f6b9cbbbfddaeeaa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87ef4c88e4f4048975ffd2edff484e6",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3073778c52f9432492d1f9e446440e20",
            "value": 819
          }
        },
        "99b892d921d8408a8d6d795d706a55a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52fab5b69a4d47a89c90874da8c39977",
            "placeholder": "​",
            "style": "IPY_MODEL_f987516d481b43e78b8661ec5833d913",
            "value": " 819/819 [00:00&lt;00:00, 2028.94 examples/s]"
          }
        },
        "379f5f2448d84d709169c0a516170329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a4b53c890b4180ac72b2cffd8f47e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538d907a219b42ca845805d65b762b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c87ef4c88e4f4048975ffd2edff484e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3073778c52f9432492d1f9e446440e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52fab5b69a4d47a89c90874da8c39977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f987516d481b43e78b8661ec5833d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets evaluate transformers rouge-score nltk py7zr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj2V75uNwWAT",
        "outputId": "c3b4d1d0-ea72-421e-c565-a284f12f3f81",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:04.518619Z",
          "iopub.execute_input": "2024-08-29T09:13:04.519Z",
          "iopub.status.idle": "2024-08-29T09:13:21.468643Z",
          "shell.execute_reply.started": "2024-08-29T09:13:04.51895Z",
          "shell.execute_reply": "2024-08-29T09:13:21.467719Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a9a7b559a70ea8d01e05c355b5cbfe1d2bb55955d98bcb5583056f90381d7c5e\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score, evaluate\nSuccessfully installed evaluate-0.4.2 rouge-score-0.1.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq,  \\\n",
        "        Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import torch"
      ],
      "metadata": {
        "id": "fzLTG_0zBf80",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:37.873416Z",
          "iopub.execute_input": "2024-08-29T09:13:37.873838Z",
          "iopub.status.idle": "2024-08-29T09:13:37.882648Z",
          "shell.execute_reply.started": "2024-08-29T09:13:37.873796Z",
          "shell.execute_reply": "2024-08-29T09:13:37.88186Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxCGExsI5Zmy",
        "outputId": "2b570abb-c674-4bae-c820-e741a8f9673c",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:36.665514Z",
          "iopub.execute_input": "2024-08-29T09:13:36.665848Z",
          "iopub.status.idle": "2024-08-29T09:13:37.871399Z",
          "shell.execute_reply.started": "2024-08-29T09:13:36.665813Z",
          "shell.execute_reply": "2024-08-29T09:13:37.870463Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42"
      ],
      "metadata": {
        "id": "tcHlWBj21ZeS",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:39.456644Z",
          "iopub.execute_input": "2024-08-29T09:13:39.457138Z",
          "iopub.status.idle": "2024-08-29T09:13:39.461681Z",
          "shell.execute_reply.started": "2024-08-29T09:13:39.457101Z",
          "shell.execute_reply": "2024-08-29T09:13:39.460734Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Metric For evaluating Performance"
      ],
      "metadata": {
        "id": "2MFFIgdr1d6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ab7b36b6e9aa448b9b402a74612d08be"
          ]
        },
        "id": "1kpFtpNTzM2-",
        "outputId": "5d594c49-0c0f-4596-ee18-bd7f405dd240",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:39.462919Z",
          "iopub.execute_input": "2024-08-29T09:13:39.463285Z",
          "iopub.status.idle": "2024-08-29T09:13:40.030267Z",
          "shell.execute_reply.started": "2024-08-29T09:13:39.463242Z",
          "shell.execute_reply": "2024-08-29T09:13:40.02883Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/1438680113.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7b36b6e9aa448b9b402a74612d08be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "bvqeWmTv1mvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"samsum\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "qjW-quB0zeX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "574dc343aa354ff9926b5f2b1cbed811",
            "be9c0dcd458b4d7fb70948316111ffa0",
            "1aa449a5544243f9921bea52075f894e",
            "a03b39d9dd3344f49bdd485bc238e2ee",
            "20f301f6b4da44b9947336d92907393b",
            "534128d9cdf0405aa47fe07c463a9b83"
          ]
        },
        "outputId": "5c215cfe-f87d-4f5b-fa72-67ef604b84fd",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:40.031851Z",
          "iopub.execute_input": "2024-08-29T09:13:40.033342Z",
          "iopub.status.idle": "2024-08-29T09:13:45.700176Z",
          "shell.execute_reply.started": "2024-08-29T09:13:40.033298Z",
          "shell.execute_reply": "2024-08-29T09:13:45.699355Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/3.36k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "574dc343aa354ff9926b5f2b1cbed811"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/7.04k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be9c0dcd458b4d7fb70948316111ffa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aa449a5544243f9921bea52075f894e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a03b39d9dd3344f49bdd485bc238e2ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20f301f6b4da44b9947336d92907393b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "534128d9cdf0405aa47fe07c463a9b83"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Sample"
      ],
      "metadata": {
        "id": "qC8g3dqu3n2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_sample(random_state=None):\n",
        "    return dataset[\"train\"].shuffle(seed=random_state)[1]"
      ],
      "metadata": {
        "id": "hXMzGtAv34NY",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:37:06.511945Z",
          "iopub.execute_input": "2024-08-29T09:37:06.512863Z",
          "iopub.status.idle": "2024-08-29T09:37:06.517502Z",
          "shell.execute_reply.started": "2024-08-29T09:37:06.512819Z",
          "shell.execute_reply": "2024-08-29T09:37:06.516592Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = get_random_sample(random_state=random_state)\n",
        "print(\"Dialogue:\")\n",
        "print(sample[\"dialogue\"])\n",
        "print(f'\\nSummary: {sample[\"summary\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txp_3OLW1s3I",
        "outputId": "253bca0c-9671-4448-9653-f300fc37f097",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:37:07.147885Z",
          "iopub.execute_input": "2024-08-29T09:37:07.148755Z",
          "iopub.status.idle": "2024-08-29T09:37:07.157235Z",
          "shell.execute_reply.started": "2024-08-29T09:37:07.148715Z",
          "shell.execute_reply": "2024-08-29T09:37:07.15634Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Dialogue:\nWendy: What's up?\nSimon: Nothing much. I'm painting my cupboards. \nAngela: Cool what colour?\nSimon: Green.\nBen: I'm just chilling in the garden. \nAngela: Nice weekend! I'm about to meet Chris.\nWendy: Say hello from me!\nAngela: Will do! And how is your weekend, Wendy?\nWendy: Very lazy... The week was hard at work, I really needed some rest. \nBen: We should all come and visit Simon in his new apartment!\nSimon: You are welcome, guys! Whenever you wish.\nBen: I should be in Bournemouth next week. \nSimon: I'm not going anywhere :-)\nBen: Cool, I'll call you next week. \n\nSummary: This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Evaluation and preprocessing functions"
      ],
      "metadata": {
        "id": "T91tBpLCuQv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline_summaries(dataset, metric, column_text=\"dialogue\",\n",
        "                                column_summary=\"summary\"):\n",
        "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
        "    score = metric.compute()\n",
        "    return score\n",
        "\n",
        "def chunks(list_of_elements, batch_size):\n",
        "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def evaluate_summaries_baseline(dataset, metric,\n",
        "     column_text=\"article\",\n",
        "     column_summary=\"highlights\"):\n",
        "     summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "     metric.add_batch(predictions=summaries,\n",
        "     references=dataset[column_summary])\n",
        "     score = metric.compute()\n",
        "     return score\n",
        "\n",
        "def evaluate_model_summaries(dataset, metric, model, tokenizer, batch_size=16,\n",
        "                             device=\"cuda\", column_text=\"dialogue\", column_summary=\"summary\"):\n",
        "    dialogue_batches = list(chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for dialogue_batch, target_batch in tqdm(\n",
        "        zip(dialogue_batches, target_batches), total=len(dialogue_batches)):\n",
        "        inputs = tokenizer(dialogue_batch, max_length=1024,\n",
        "                        padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                                length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                            clean_up_tokenization_spaces=True)\n",
        "                            for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    score = metric.compute(use_stemmer=True, use_aggregator=True)\n",
        "    return score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    result = rouge_metric.compute(predictions=decoded_preds,\n",
        "                    references=decoded_labels, use_stemmer=True,\n",
        "                    use_aggregator=True)\n",
        "\n",
        "    # # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "def preprocess_function(example_batch, max_input_length=1024, max_target_length=128):\n",
        "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=max_input_length,\n",
        "                                truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=max_target_length,\n",
        "                                truncation=True)\n",
        "\n",
        "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]\n",
        "    return input_encodings"
      ],
      "metadata": {
        "id": "OrJPRRRruQFR",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:13:45.73919Z",
          "iopub.execute_input": "2024-08-29T09:13:45.73948Z",
          "iopub.status.idle": "2024-08-29T09:13:45.750762Z",
          "shell.execute_reply.started": "2024-08-29T09:13:45.739449Z",
          "shell.execute_reply": "2024-08-29T09:13:45.749878Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Baseline performance on the test set\n",
        "For comparisons with fine-tuned model."
      ],
      "metadata": {
        "id": "6k5JQOZyEkEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Evaluate Model's performance on the test set\n",
        "For comparisons with fine-tuned model."
      ],
      "metadata": {
        "id": "E8KMxaDIEkEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try out a Pretrained Model"
      ],
      "metadata": {
        "id": "oOjIDcwH6APP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "rfk4vzyi0R_7",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:02.097403Z",
          "iopub.execute_input": "2024-08-29T09:14:02.098013Z",
          "iopub.status.idle": "2024-08-29T09:14:02.126605Z",
          "shell.execute_reply.started": "2024-08-29T09:14:02.097956Z",
          "shell.execute_reply": "2024-08-29T09:14:02.125585Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"google/pegasus-cnn_dailymail\""
      ],
      "metadata": {
        "id": "yEac5JDL1srI",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:46:36.571927Z",
          "iopub.execute_input": "2024-08-29T09:46:36.572932Z",
          "iopub.status.idle": "2024-08-29T09:46:36.577835Z",
          "shell.execute_reply.started": "2024-08-29T09:46:36.572879Z",
          "shell.execute_reply": "2024-08-29T09:46:36.576769Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "pipe = pipeline(\"summarization\", model=model_ckpt, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atnqTyNGflfW",
        "outputId": "f4690994-d779-4c97-883b-ec8864a20a82",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:49:21.206368Z",
          "iopub.execute_input": "2024-08-29T09:49:21.207045Z",
          "iopub.status.idle": "2024-08-29T09:49:32.424741Z",
          "shell.execute_reply.started": "2024-08-29T09:49:21.207004Z",
          "shell.execute_reply": "2024-08-29T09:49:32.423915Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample[\"dialogue\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T09:38:02.686587Z",
          "iopub.execute_input": "2024-08-29T09:38:02.687068Z",
          "iopub.status.idle": "2024-08-29T09:38:02.692399Z",
          "shell.execute_reply.started": "2024-08-29T09:38:02.68702Z",
          "shell.execute_reply": "2024-08-29T09:38:02.691511Z"
        },
        "trusted": true,
        "id": "03BbMx4jEkEY",
        "outputId": "49f5fdc9-02f2-4ebb-e637-15e65bad0f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Wendy: What's up?\nSimon: Nothing much. I'm painting my cupboards. \nAngela: Cool what colour?\nSimon: Green.\nBen: I'm just chilling in the garden. \nAngela: Nice weekend! I'm about to meet Chris.\nWendy: Say hello from me!\nAngela: Will do! And how is your weekend, Wendy?\nWendy: Very lazy... The week was hard at work, I really needed some rest. \nBen: We should all come and visit Simon in his new apartment!\nSimon: You are welcome, guys! Whenever you wish.\nBen: I should be in Bournemouth next week. \nSimon: I'm not going anywhere :-)\nBen: Cool, I'll call you next week. \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[\"summary\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T09:38:16.967357Z",
          "iopub.execute_input": "2024-08-29T09:38:16.968081Z",
          "iopub.status.idle": "2024-08-29T09:38:16.973831Z",
          "shell.execute_reply.started": "2024-08-29T09:38:16.968039Z",
          "shell.execute_reply": "2024-08-29T09:38:16.972861Z"
        },
        "trusted": true,
        "id": "bg-BOEFPEkEY",
        "outputId": "274636f6-da04-4528-e61f-6951ff0bad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 59,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_out = pipe(sample[\"dialogue\"])\n",
        "pipe_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T09:50:43.940681Z",
          "iopub.execute_input": "2024-08-29T09:50:43.94159Z",
          "iopub.status.idle": "2024-08-29T09:50:44.808128Z",
          "shell.execute_reply.started": "2024-08-29T09:50:43.941536Z",
          "shell.execute_reply": "2024-08-29T09:50:44.807185Z"
        },
        "trusted": true,
        "id": "XLQmX-q_EkEZ",
        "outputId": "5a0b0900-4b14-4473-f568-b3074921075f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'summary_text': 'Simon is painting his cupboards. Ben is chilling in the garden. Angela is about to meet Chris. Wendy is lazy. Simon should be in Bournemouth next week.'}]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model's performance on the test set\n",
        "\n",
        "For comparisons with fine-tuned model."
      ],
      "metadata": {
        "id": "ReIpiKRgEkEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "score = evaluate_model_summaries(dataset[\"test\"], rouge_metric, model, tokenizer,\n",
        "            batch_size=2, device=device, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "rouge_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1T6ye1mffw5",
        "outputId": "6e579f0a-a22d-45e8-bad8-6ca741a9855c",
        "execution": {
          "iopub.status.busy": "2024-08-29T06:57:14.740872Z",
          "iopub.execute_input": "2024-08-29T06:57:14.741175Z",
          "iopub.status.idle": "2024-08-29T07:08:58.083394Z",
          "shell.execute_reply.started": "2024-08-29T06:57:14.741145Z",
          "shell.execute_reply": "2024-08-29T07:08:58.082426Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 410/410 [11:39<00:00,  1.71s/it]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'rouge1': 0.3056591654023485,\n 'rouge2': 0.09154776946834249,\n 'rougeL': 0.23558434106338993,\n 'rougeLsum': 0.23538792149845683}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning Model"
      ],
      "metadata": {
        "id": "W8qgiPeSCTUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize dataset\n",
        "preprocess_kwargs = {\n",
        "    \"max_input_length\": 1024,\n",
        "    \"max_target_length\": 128\n",
        "}\n",
        "tokenized_datasets = dataset.map(preprocess_function, fn_kwargs=preprocess_kwargs, batched=True)\n",
        "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "6Jv5Ebgz7Nwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "112f6a8c7922410e8c72c35f4502a5cc",
            "c15ec4f9e29f4835b085bb0223b5ebfc",
            "da7601058b3d40f6b9cbbbfddaeeaa5c",
            "99b892d921d8408a8d6d795d706a55a0",
            "379f5f2448d84d709169c0a516170329",
            "40a4b53c890b4180ac72b2cffd8f47e2",
            "538d907a219b42ca845805d65b762b2f",
            "c87ef4c88e4f4048975ffd2edff484e6",
            "3073778c52f9432492d1f9e446440e20",
            "52fab5b69a4d47a89c90874da8c39977",
            "f987516d481b43e78b8661ec5833d913",
            "9340bd7e6e2f42cca01fc45bdcab771c"
          ]
        },
        "outputId": "443b16d3-1bfa-4ead-d1d6-c5d6f59f8c14",
        "execution": {
          "iopub.status.busy": "2024-08-29T10:14:05.19266Z",
          "iopub.execute_input": "2024-08-29T10:14:05.193496Z",
          "iopub.status.idle": "2024-08-29T10:14:09.597297Z",
          "shell.execute_reply.started": "2024-08-29T10:14:05.193454Z",
          "shell.execute_reply": "2024-08-29T10:14:09.596459Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9340bd7e6e2f42cca01fc45bdcab771c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "batch_size = 4\n",
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "fine_tuned_model_name = f\"{model_name}-finetuned-samsum\"\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    fine_tuned_model_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Ugy548EzNM",
        "outputId": "04360e58-b53b-473f-d796-c8efd173cb74",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:37.922092Z",
          "iopub.execute_input": "2024-08-29T09:14:37.922398Z",
          "iopub.status.idle": "2024-08-29T09:14:37.955808Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.922366Z",
          "shell.execute_reply": "2024-08-29T09:14:37.954946Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup data collator\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "ojkZR48GIE4U",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:37.95686Z",
          "iopub.execute_input": "2024-08-29T09:14:37.957163Z",
          "iopub.status.idle": "2024-08-29T09:14:37.961564Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.957129Z",
          "shell.execute_reply": "2024-08-29T09:14:37.960583Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a smaller subset of the dataset to speed up the fine tuning\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(500))"
      ],
      "metadata": {
        "id": "VhJ0XwOs2Ruy",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:37.96268Z",
          "iopub.execute_input": "2024-08-29T09:14:37.962966Z",
          "iopub.status.idle": "2024-08-29T09:14:37.997326Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.962936Z",
          "shell.execute_reply": "2024-08-29T09:14:37.996446Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    data_collator=seq2seq_data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "GVWqwL4GQdjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a575487b-aa45-4c2b-90f5-283027e6f13d",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:37.998603Z",
          "iopub.execute_input": "2024-08-29T09:14:37.999321Z",
          "iopub.status.idle": "2024-08-29T09:14:38.033778Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.999277Z",
          "shell.execute_reply": "2024-08-29T09:14:38.032934Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and save model\n",
        "trainer.train\n",
        "trainer.save_model(fine_tuned_model_name)"
      ],
      "metadata": {
        "id": "880CEBqvQncm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "189e4a5e-fb4f-48e5-9126-a9e03252ba28",
        "execution": {
          "iopub.status.busy": "2024-08-29T09:14:38.059639Z",
          "iopub.execute_input": "2024-08-29T09:14:38.059943Z",
          "iopub.status.idle": "2024-08-29T09:22:05.602321Z",
          "shell.execute_reply.started": "2024-08-29T09:14:38.059901Z",
          "shell.execute_reply": "2024-08-29T09:22:05.601407Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 07:25, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.782825</td>\n      <td>38.642100</td>\n      <td>17.062500</td>\n      <td>30.964300</td>\n      <td>35.396700</td>\n      <td>42.252000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
          "output_type": "stream"
        },
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=250, training_loss=2.220920166015625, metrics={'train_runtime': 446.6151, 'train_samples_per_second': 2.239, 'train_steps_per_second': 0.56, 'total_flos': 708336399384576.0, 'train_loss': 2.220920166015625, 'epoch': 1.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying out fine-tuned Model"
      ],
      "metadata": {
        "id": "-jTxJSuLEkEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        fine_tuned_model_name).to(device)\n",
        "pipe = pipeline(\"summarization\", model=fine_tuned_model_name, device=device)"
      ],
      "metadata": {
        "id": "btTF82hTrxIx",
        "execution": {
          "iopub.status.busy": "2024-08-29T10:25:30.439266Z",
          "iopub.execute_input": "2024-08-29T10:25:30.439774Z",
          "iopub.status.idle": "2024-08-29T10:25:46.508609Z",
          "shell.execute_reply.started": "2024-08-29T10:25:30.439719Z",
          "shell.execute_reply": "2024-08-29T10:25:46.507579Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample[\"dialogue\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T10:25:46.511102Z",
          "iopub.execute_input": "2024-08-29T10:25:46.511385Z",
          "iopub.status.idle": "2024-08-29T10:25:46.516579Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.511354Z",
          "shell.execute_reply": "2024-08-29T10:25:46.515606Z"
        },
        "trusted": true,
        "id": "JBFtuuv_EkEc",
        "outputId": "0891d244-5905-47b5-a140-477e524ec2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Wendy: What's up?\nSimon: Nothing much. I'm painting my cupboards. \nAngela: Cool what colour?\nSimon: Green.\nBen: I'm just chilling in the garden. \nAngela: Nice weekend! I'm about to meet Chris.\nWendy: Say hello from me!\nAngela: Will do! And how is your weekend, Wendy?\nWendy: Very lazy... The week was hard at work, I really needed some rest. \nBen: We should all come and visit Simon in his new apartment!\nSimon: You are welcome, guys! Whenever you wish.\nBen: I should be in Bournemouth next week. \nSimon: I'm not going anywhere :-)\nBen: Cool, I'll call you next week. \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[\"summary\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T10:25:46.517499Z",
          "iopub.execute_input": "2024-08-29T10:25:46.517837Z",
          "iopub.status.idle": "2024-08-29T10:25:46.530527Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.517804Z",
          "shell.execute_reply": "2024-08-29T10:25:46.52968Z"
        },
        "trusted": true,
        "id": "ywPuRC_DEkEc",
        "outputId": "b2f8ea5a-ad8b-454c-defb-d9e0c380b043"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 88,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_out = pipe(sample[\"dialogue\"])\n",
        "pipe_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T10:25:46.532254Z",
          "iopub.execute_input": "2024-08-29T10:25:46.532552Z",
          "iopub.status.idle": "2024-08-29T10:25:47.419845Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.532519Z",
          "shell.execute_reply": "2024-08-29T10:25:47.418894Z"
        },
        "trusted": true,
        "id": "aBs-uJkmEkEc",
        "outputId": "6230df9d-b54c-4d3f-a768-0ad7de5f90fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 89,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'summary_text': 'Simon is painting his cupboards. Ben is chilling in the garden. Angela is about to meet Chris. Wendy is lazy. Simon should be in Bournemouth next week.'}]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Fine-tuned model's performance on the test set"
      ],
      "metadata": {
        "id": "637BzHddEkEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "score = evaluate_model_summaries(dataset[\"test\"], rouge_metric, model, tokenizer,\n",
        "            batch_size=2, device=device, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "rouge_dict"
      ],
      "metadata": {
        "id": "2fG5E7DlQ2SW",
        "execution": {
          "iopub.status.busy": "2024-08-29T07:16:51.470605Z",
          "iopub.execute_input": "2024-08-29T07:16:51.471194Z",
          "iopub.status.idle": "2024-08-29T07:24:59.802005Z",
          "shell.execute_reply.started": "2024-08-29T07:16:51.471144Z",
          "shell.execute_reply": "2024-08-29T07:24:59.801033Z"
        },
        "trusted": true,
        "outputId": "cad607e2-115a-47b0-858b-7f3e018678fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 410/410 [08:05<00:00,  1.18s/it]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'rouge1': 0.3830135144299003,\n 'rouge2': 0.16436031776335036,\n 'rougeL': 0.30285047062777837,\n 'rougeLsum': 0.3033148106739478}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are better than that of the pretrained model."
      ],
      "metadata": {
        "id": "Xnk-3E48zx2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Play Around"
      ],
      "metadata": {
        "id": "cyGWlFHFEkEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 48\n",
        "sample = get_random_sample()\n",
        "print(\"Dialogue:\")\n",
        "print(sample[\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(sample[\"summary\"])\n",
        "print(\"\\n\\nGenerated Summary\")\n",
        "pipe_out = pipe(sample[\"dialogue\"], max_length=max_length)\n",
        "print(pipe_out[0][\"summary_text\"].replace(\"<n>\", \"\\n\"))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-29T12:15:58.815615Z",
          "iopub.execute_input": "2024-08-29T12:15:58.816035Z",
          "iopub.status.idle": "2024-08-29T12:15:59.729808Z",
          "shell.execute_reply.started": "2024-08-29T12:15:58.815972Z",
          "shell.execute_reply": "2024-08-29T12:15:59.728772Z"
        },
        "trusted": true,
        "id": "kvS_kOPPEkEj",
        "outputId": "bc044c9d-2062-49f9-8403-f53d1feeb290"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Dialogue:\nAline: Ali, where did you put the keys to the basement?\nAli: Oh, I have them with me... Sorry, I forgot to out them back...\nAline: ...\nAline: What time are you coming back?\nAli: 7:00\nAline: Don't do that again, please...\n\nSummary:\nAline wonders where Ali left the keys to the basement, and he has them with him. Ali is coming back at 7:00, which Aline isn't happy about. \n\n\nGenerated Summary\nAli forgot to put the keys to the basement in the basement. He will return to the basement at 7 p.m. on Friday. Aline will be waiting for him at the basement.\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}