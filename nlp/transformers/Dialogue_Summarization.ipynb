{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:04.519Z",
          "iopub.status.busy": "2024-08-29T09:13:04.518619Z",
          "iopub.status.idle": "2024-08-29T09:13:21.468643Z",
          "shell.execute_reply": "2024-08-29T09:13:21.467719Z",
          "shell.execute_reply.started": "2024-08-29T09:13:04.51895Z"
        },
        "id": "mj2V75uNwWAT",
        "outputId": "c3b4d1d0-ea72-421e-c565-a284f12f3f81",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a9a7b559a70ea8d01e05c355b5cbfe1d2bb55955d98bcb5583056f90381d7c5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score, evaluate\n",
            "Successfully installed evaluate-0.4.2 rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets evaluate transformers rouge-score nltk py7zr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:37.873838Z",
          "iopub.status.busy": "2024-08-29T09:13:37.873416Z",
          "iopub.status.idle": "2024-08-29T09:13:37.882648Z",
          "shell.execute_reply": "2024-08-29T09:13:37.88186Z",
          "shell.execute_reply.started": "2024-08-29T09:13:37.873796Z"
        },
        "id": "fzLTG_0zBf80",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq,  \\\n",
        "        Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:36.665848Z",
          "iopub.status.busy": "2024-08-29T09:13:36.665514Z",
          "iopub.status.idle": "2024-08-29T09:13:37.871399Z",
          "shell.execute_reply": "2024-08-29T09:13:37.870463Z",
          "shell.execute_reply.started": "2024-08-29T09:13:36.665813Z"
        },
        "id": "QxCGExsI5Zmy",
        "outputId": "2b570abb-c674-4bae-c820-e741a8f9673c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:39.457138Z",
          "iopub.status.busy": "2024-08-29T09:13:39.456644Z",
          "iopub.status.idle": "2024-08-29T09:13:39.461681Z",
          "shell.execute_reply": "2024-08-29T09:13:39.460734Z",
          "shell.execute_reply.started": "2024-08-29T09:13:39.457101Z"
        },
        "id": "tcHlWBj21ZeS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "random_state = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MFFIgdr1d6o"
      },
      "source": [
        "### Define Metric For evaluating Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ab7b36b6e9aa448b9b402a74612d08be"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:39.463285Z",
          "iopub.status.busy": "2024-08-29T09:13:39.462919Z",
          "iopub.status.idle": "2024-08-29T09:13:40.030267Z",
          "shell.execute_reply": "2024-08-29T09:13:40.02883Z",
          "shell.execute_reply.started": "2024-08-29T09:13:39.463242Z"
        },
        "id": "1kpFtpNTzM2-",
        "outputId": "5d594c49-0c0f-4596-ee18-bd7f405dd240",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36/1438680113.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab7b36b6e9aa448b9b402a74612d08be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvqeWmTv1mvP"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "574dc343aa354ff9926b5f2b1cbed811",
            "be9c0dcd458b4d7fb70948316111ffa0",
            "1aa449a5544243f9921bea52075f894e",
            "a03b39d9dd3344f49bdd485bc238e2ee",
            "20f301f6b4da44b9947336d92907393b",
            "534128d9cdf0405aa47fe07c463a9b83"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:40.033342Z",
          "iopub.status.busy": "2024-08-29T09:13:40.031851Z",
          "iopub.status.idle": "2024-08-29T09:13:45.700176Z",
          "shell.execute_reply": "2024-08-29T09:13:45.699355Z",
          "shell.execute_reply.started": "2024-08-29T09:13:40.033298Z"
        },
        "id": "qjW-quB0zeX5",
        "outputId": "5c215cfe-f87d-4f5b-fa72-67ef604b84fd",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "574dc343aa354ff9926b5f2b1cbed811",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.36k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be9c0dcd458b4d7fb70948316111ffa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.04k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa449a5544243f9921bea52075f894e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a03b39d9dd3344f49bdd485bc238e2ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20f301f6b4da44b9947336d92907393b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "534128d9cdf0405aa47fe07c463a9b83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(\"samsum\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC8g3dqu3n2o"
      },
      "source": [
        "### View Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:37:06.512863Z",
          "iopub.status.busy": "2024-08-29T09:37:06.511945Z",
          "iopub.status.idle": "2024-08-29T09:37:06.517502Z",
          "shell.execute_reply": "2024-08-29T09:37:06.516592Z",
          "shell.execute_reply.started": "2024-08-29T09:37:06.512819Z"
        },
        "id": "hXMzGtAv34NY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_random_sample(random_state=None):\n",
        "    return dataset[\"train\"].shuffle(seed=random_state)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:37:07.148755Z",
          "iopub.status.busy": "2024-08-29T09:37:07.147885Z",
          "iopub.status.idle": "2024-08-29T09:37:07.157235Z",
          "shell.execute_reply": "2024-08-29T09:37:07.15634Z",
          "shell.execute_reply.started": "2024-08-29T09:37:07.148715Z"
        },
        "id": "Txp_3OLW1s3I",
        "outputId": "253bca0c-9671-4448-9653-f300fc37f097",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dialogue:\n",
            "Wendy: What's up?\n",
            "Simon: Nothing much. I'm painting my cupboards. \n",
            "Angela: Cool what colour?\n",
            "Simon: Green.\n",
            "Ben: I'm just chilling in the garden. \n",
            "Angela: Nice weekend! I'm about to meet Chris.\n",
            "Wendy: Say hello from me!\n",
            "Angela: Will do! And how is your weekend, Wendy?\n",
            "Wendy: Very lazy... The week was hard at work, I really needed some rest. \n",
            "Ben: We should all come and visit Simon in his new apartment!\n",
            "Simon: You are welcome, guys! Whenever you wish.\n",
            "Ben: I should be in Bournemouth next week. \n",
            "Simon: I'm not going anywhere :-)\n",
            "Ben: Cool, I'll call you next week. \n",
            "\n",
            "Summary: This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.\n"
          ]
        }
      ],
      "source": [
        "sample = get_random_sample(random_state=random_state)\n",
        "print(\"Dialogue:\")\n",
        "print(sample[\"dialogue\"])\n",
        "print(f'\\nSummary: {sample[\"summary\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T91tBpLCuQv8"
      },
      "source": [
        "### Setup Evaluation and preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:13:45.73948Z",
          "iopub.status.busy": "2024-08-29T09:13:45.73919Z",
          "iopub.status.idle": "2024-08-29T09:13:45.750762Z",
          "shell.execute_reply": "2024-08-29T09:13:45.749878Z",
          "shell.execute_reply.started": "2024-08-29T09:13:45.739449Z"
        },
        "id": "OrJPRRRruQFR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_baseline_summaries(dataset, metric, column_text=\"dialogue\",\n",
        "                                column_summary=\"summary\"):\n",
        "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
        "    score = metric.compute()\n",
        "    return score\n",
        "\n",
        "def chunks(list_of_elements, batch_size):\n",
        "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def evaluate_summaries_baseline(dataset, metric,\n",
        "     column_text=\"article\",\n",
        "     column_summary=\"highlights\"):\n",
        "     summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "     metric.add_batch(predictions=summaries,\n",
        "     references=dataset[column_summary])\n",
        "     score = metric.compute()\n",
        "     return score\n",
        "\n",
        "def evaluate_model_summaries(dataset, metric, model, tokenizer, batch_size=16,\n",
        "                             device=\"cuda\", column_text=\"dialogue\", column_summary=\"summary\"):\n",
        "    dialogue_batches = list(chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for dialogue_batch, target_batch in tqdm(\n",
        "        zip(dialogue_batches, target_batches), total=len(dialogue_batches)):\n",
        "        inputs = tokenizer(dialogue_batch, max_length=1024,\n",
        "                        padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                                length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                            clean_up_tokenization_spaces=True)\n",
        "                            for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    score = metric.compute(use_stemmer=True, use_aggregator=True)\n",
        "    return score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    result = rouge_metric.compute(predictions=decoded_preds,\n",
        "                    references=decoded_labels, use_stemmer=True,\n",
        "                    use_aggregator=True)\n",
        "\n",
        "    # # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "def preprocess_function(example_batch, max_input_length=1024, max_target_length=128):\n",
        "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=max_input_length,\n",
        "                                truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=max_target_length,\n",
        "                                truncation=True)\n",
        "\n",
        "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]\n",
        "    return input_encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k5JQOZyEkEV"
      },
      "source": [
        "### Evaluate Baseline performance on the test set\n",
        "For comparisons with fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8KMxaDIEkEW"
      },
      "outputs": [],
      "source": [
        "Evaluate Model's performance on the test set\n",
        "For comparisons with fine-tuned model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOjIDcwH6APP"
      },
      "source": [
        "### Try out a Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:02.098013Z",
          "iopub.status.busy": "2024-08-29T09:14:02.097403Z",
          "iopub.status.idle": "2024-08-29T09:14:02.126605Z",
          "shell.execute_reply": "2024-08-29T09:14:02.125585Z",
          "shell.execute_reply.started": "2024-08-29T09:14:02.097956Z"
        },
        "id": "rfk4vzyi0R_7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:46:36.572932Z",
          "iopub.status.busy": "2024-08-29T09:46:36.571927Z",
          "iopub.status.idle": "2024-08-29T09:46:36.577835Z",
          "shell.execute_reply": "2024-08-29T09:46:36.576769Z",
          "shell.execute_reply.started": "2024-08-29T09:46:36.572879Z"
        },
        "id": "yEac5JDL1srI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_ckpt = \"google/pegasus-cnn_dailymail\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:49:21.207045Z",
          "iopub.status.busy": "2024-08-29T09:49:21.206368Z",
          "iopub.status.idle": "2024-08-29T09:49:32.424741Z",
          "shell.execute_reply": "2024-08-29T09:49:32.423915Z",
          "shell.execute_reply.started": "2024-08-29T09:49:21.207004Z"
        },
        "id": "atnqTyNGflfW",
        "outputId": "f4690994-d779-4c97-883b-ec8864a20a82",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "pipe = pipeline(\"summarization\", model=model_ckpt, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:38:02.687068Z",
          "iopub.status.busy": "2024-08-29T09:38:02.686587Z",
          "iopub.status.idle": "2024-08-29T09:38:02.692399Z",
          "shell.execute_reply": "2024-08-29T09:38:02.691511Z",
          "shell.execute_reply.started": "2024-08-29T09:38:02.68702Z"
        },
        "id": "03BbMx4jEkEY",
        "outputId": "49f5fdc9-02f2-4ebb-e637-15e65bad0f97",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wendy: What's up?\n",
            "Simon: Nothing much. I'm painting my cupboards. \n",
            "Angela: Cool what colour?\n",
            "Simon: Green.\n",
            "Ben: I'm just chilling in the garden. \n",
            "Angela: Nice weekend! I'm about to meet Chris.\n",
            "Wendy: Say hello from me!\n",
            "Angela: Will do! And how is your weekend, Wendy?\n",
            "Wendy: Very lazy... The week was hard at work, I really needed some rest. \n",
            "Ben: We should all come and visit Simon in his new apartment!\n",
            "Simon: You are welcome, guys! Whenever you wish.\n",
            "Ben: I should be in Bournemouth next week. \n",
            "Simon: I'm not going anywhere :-)\n",
            "Ben: Cool, I'll call you next week. \n"
          ]
        }
      ],
      "source": [
        "print(sample[\"dialogue\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:38:16.968081Z",
          "iopub.status.busy": "2024-08-29T09:38:16.967357Z",
          "iopub.status.idle": "2024-08-29T09:38:16.973831Z",
          "shell.execute_reply": "2024-08-29T09:38:16.972861Z",
          "shell.execute_reply.started": "2024-08-29T09:38:16.968039Z"
        },
        "id": "bg-BOEFPEkEY",
        "outputId": "274636f6-da04-4528-e61f-6951ff0bad32",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:50:43.94159Z",
          "iopub.status.busy": "2024-08-29T09:50:43.940681Z",
          "iopub.status.idle": "2024-08-29T09:50:44.808128Z",
          "shell.execute_reply": "2024-08-29T09:50:44.807185Z",
          "shell.execute_reply.started": "2024-08-29T09:50:43.941536Z"
        },
        "id": "XLQmX-q_EkEZ",
        "outputId": "5a0b0900-4b14-4473-f568-b3074921075f",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'Simon is painting his cupboards. Ben is chilling in the garden. Angela is about to meet Chris. Wendy is lazy. Simon should be in Bournemouth next week.'}]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_out = pipe(sample[\"dialogue\"])\n",
        "pipe_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReIpiKRgEkEZ"
      },
      "source": [
        "### Evaluate Model's performance on the test set\n",
        "\n",
        "For comparisons with fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T06:57:14.741175Z",
          "iopub.status.busy": "2024-08-29T06:57:14.740872Z",
          "iopub.status.idle": "2024-08-29T07:08:58.083394Z",
          "shell.execute_reply": "2024-08-29T07:08:58.082426Z",
          "shell.execute_reply.started": "2024-08-29T06:57:14.741145Z"
        },
        "id": "O1T6ye1mffw5",
        "outputId": "6e579f0a-a22d-45e8-bad8-6ca741a9855c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [11:39<00:00,  1.71s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': 0.3056591654023485,\n",
              " 'rouge2': 0.09154776946834249,\n",
              " 'rougeL': 0.23558434106338993,\n",
              " 'rougeLsum': 0.23538792149845683}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "score = evaluate_model_summaries(dataset[\"test\"], rouge_metric, model, tokenizer,\n",
        "            batch_size=2, device=device, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "rouge_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8qgiPeSCTUX"
      },
      "source": [
        "### Fine-Tuning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "112f6a8c7922410e8c72c35f4502a5cc",
            "c15ec4f9e29f4835b085bb0223b5ebfc",
            "da7601058b3d40f6b9cbbbfddaeeaa5c",
            "99b892d921d8408a8d6d795d706a55a0",
            "379f5f2448d84d709169c0a516170329",
            "40a4b53c890b4180ac72b2cffd8f47e2",
            "538d907a219b42ca845805d65b762b2f",
            "c87ef4c88e4f4048975ffd2edff484e6",
            "3073778c52f9432492d1f9e446440e20",
            "52fab5b69a4d47a89c90874da8c39977",
            "f987516d481b43e78b8661ec5833d913",
            "9340bd7e6e2f42cca01fc45bdcab771c"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T10:14:05.193496Z",
          "iopub.status.busy": "2024-08-29T10:14:05.19266Z",
          "iopub.status.idle": "2024-08-29T10:14:09.597297Z",
          "shell.execute_reply": "2024-08-29T10:14:09.596459Z",
          "shell.execute_reply.started": "2024-08-29T10:14:05.193454Z"
        },
        "id": "6Jv5Ebgz7Nwe",
        "outputId": "443b16d3-1bfa-4ead-d1d6-c5d6f59f8c14",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9340bd7e6e2f42cca01fc45bdcab771c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# tokenize dataset\n",
        "preprocess_kwargs = {\n",
        "    \"max_input_length\": 1024,\n",
        "    \"max_target_length\": 128\n",
        "}\n",
        "tokenized_datasets = dataset.map(preprocess_function, fn_kwargs=preprocess_kwargs, batched=True)\n",
        "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:37.922398Z",
          "iopub.status.busy": "2024-08-29T09:14:37.922092Z",
          "iopub.status.idle": "2024-08-29T09:14:37.955808Z",
          "shell.execute_reply": "2024-08-29T09:14:37.954946Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.922366Z"
        },
        "id": "-1Ugy548EzNM",
        "outputId": "04360e58-b53b-473f-d796-c8efd173cb74",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define training arguments\n",
        "batch_size = 4\n",
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "fine_tuned_model_name = f\"{model_name}-finetuned-samsum\"\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    fine_tuned_model_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:37.957163Z",
          "iopub.status.busy": "2024-08-29T09:14:37.95686Z",
          "iopub.status.idle": "2024-08-29T09:14:37.961564Z",
          "shell.execute_reply": "2024-08-29T09:14:37.960583Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.957129Z"
        },
        "id": "ojkZR48GIE4U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# setup data collator\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:37.962966Z",
          "iopub.status.busy": "2024-08-29T09:14:37.96268Z",
          "iopub.status.idle": "2024-08-29T09:14:37.997326Z",
          "shell.execute_reply": "2024-08-29T09:14:37.996446Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.962936Z"
        },
        "id": "VhJ0XwOs2Ruy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# create a smaller subset of the dataset to speed up the fine tuning\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:37.999321Z",
          "iopub.status.busy": "2024-08-29T09:14:37.998603Z",
          "iopub.status.idle": "2024-08-29T09:14:38.033778Z",
          "shell.execute_reply": "2024-08-29T09:14:38.032934Z",
          "shell.execute_reply.started": "2024-08-29T09:14:37.999277Z"
        },
        "id": "GVWqwL4GQdjh",
        "outputId": "a575487b-aa45-4c2b-90f5-283027e6f13d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# setup trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    data_collator=seq2seq_data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "execution": {
          "iopub.execute_input": "2024-08-29T09:14:38.059943Z",
          "iopub.status.busy": "2024-08-29T09:14:38.059639Z",
          "iopub.status.idle": "2024-08-29T09:22:05.602321Z",
          "shell.execute_reply": "2024-08-29T09:22:05.601407Z",
          "shell.execute_reply.started": "2024-08-29T09:14:38.059901Z"
        },
        "id": "880CEBqvQncm",
        "outputId": "189e4a5e-fb4f-48e5-9126-a9e03252ba28",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 07:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.782825</td>\n",
              "      <td>38.642100</td>\n",
              "      <td>17.062500</td>\n",
              "      <td>30.964300</td>\n",
              "      <td>35.396700</td>\n",
              "      <td>42.252000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=250, training_loss=2.220920166015625, metrics={'train_runtime': 446.6151, 'train_samples_per_second': 2.239, 'train_steps_per_second': 0.56, 'total_flos': 708336399384576.0, 'train_loss': 2.220920166015625, 'epoch': 1.0})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train and save model\n",
        "trainer.train\n",
        "trainer.save_model(fine_tuned_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jTxJSuLEkEb"
      },
      "source": [
        "### Trying out fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T10:25:30.439774Z",
          "iopub.status.busy": "2024-08-29T10:25:30.439266Z",
          "iopub.status.idle": "2024-08-29T10:25:46.508609Z",
          "shell.execute_reply": "2024-08-29T10:25:46.507579Z",
          "shell.execute_reply.started": "2024-08-29T10:25:30.439719Z"
        },
        "id": "btTF82hTrxIx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        fine_tuned_model_name).to(device)\n",
        "pipe = pipeline(\"summarization\", model=fine_tuned_model_name, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T10:25:46.511385Z",
          "iopub.status.busy": "2024-08-29T10:25:46.511102Z",
          "iopub.status.idle": "2024-08-29T10:25:46.516579Z",
          "shell.execute_reply": "2024-08-29T10:25:46.515606Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.511354Z"
        },
        "id": "JBFtuuv_EkEc",
        "outputId": "0891d244-5905-47b5-a140-477e524ec2b3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wendy: What's up?\n",
            "Simon: Nothing much. I'm painting my cupboards. \n",
            "Angela: Cool what colour?\n",
            "Simon: Green.\n",
            "Ben: I'm just chilling in the garden. \n",
            "Angela: Nice weekend! I'm about to meet Chris.\n",
            "Wendy: Say hello from me!\n",
            "Angela: Will do! And how is your weekend, Wendy?\n",
            "Wendy: Very lazy... The week was hard at work, I really needed some rest. \n",
            "Ben: We should all come and visit Simon in his new apartment!\n",
            "Simon: You are welcome, guys! Whenever you wish.\n",
            "Ben: I should be in Bournemouth next week. \n",
            "Simon: I'm not going anywhere :-)\n",
            "Ben: Cool, I'll call you next week. \n"
          ]
        }
      ],
      "source": [
        "print(sample[\"dialogue\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T10:25:46.517837Z",
          "iopub.status.busy": "2024-08-29T10:25:46.517499Z",
          "iopub.status.idle": "2024-08-29T10:25:46.530527Z",
          "shell.execute_reply": "2024-08-29T10:25:46.52968Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.517804Z"
        },
        "id": "ywPuRC_DEkEc",
        "outputId": "b2f8ea5a-ad8b-454c-defb-d9e0c380b043",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T10:25:46.532552Z",
          "iopub.status.busy": "2024-08-29T10:25:46.532254Z",
          "iopub.status.idle": "2024-08-29T10:25:47.419845Z",
          "shell.execute_reply": "2024-08-29T10:25:47.418894Z",
          "shell.execute_reply.started": "2024-08-29T10:25:46.532519Z"
        },
        "id": "aBs-uJkmEkEc",
        "outputId": "6230df9d-b54c-4d3f-a768-0ad7de5f90fb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'Simon is painting his cupboards. Ben is chilling in the garden. Angela is about to meet Chris. Wendy is lazy. Simon should be in Bournemouth next week.'}]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_out = pipe(sample[\"dialogue\"])\n",
        "pipe_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637BzHddEkEc"
      },
      "source": [
        "### Evaluate Fine-tuned model's performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T07:16:51.471194Z",
          "iopub.status.busy": "2024-08-29T07:16:51.470605Z",
          "iopub.status.idle": "2024-08-29T07:24:59.802005Z",
          "shell.execute_reply": "2024-08-29T07:24:59.801033Z",
          "shell.execute_reply.started": "2024-08-29T07:16:51.471144Z"
        },
        "id": "2fG5E7DlQ2SW",
        "outputId": "cad607e2-115a-47b0-858b-7f3e018678fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [08:05<00:00,  1.18s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': 0.3830135144299003,\n",
              " 'rouge2': 0.16436031776335036,\n",
              " 'rougeL': 0.30285047062777837,\n",
              " 'rougeLsum': 0.3033148106739478}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "score = evaluate_model_summaries(dataset[\"test\"], rouge_metric, model, tokenizer,\n",
        "            batch_size=2, device=device, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "rouge_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnk-3E48zx2t"
      },
      "source": [
        "The results are better than that of the pretrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyGWlFHFEkEj"
      },
      "source": [
        "#### Play Around"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T12:15:58.816035Z",
          "iopub.status.busy": "2024-08-29T12:15:58.815615Z",
          "iopub.status.idle": "2024-08-29T12:15:59.729808Z",
          "shell.execute_reply": "2024-08-29T12:15:59.728772Z",
          "shell.execute_reply.started": "2024-08-29T12:15:58.815972Z"
        },
        "id": "kvS_kOPPEkEj",
        "outputId": "bc044c9d-2062-49f9-8403-f53d1feeb290",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dialogue:\n",
            "Aline: Ali, where did you put the keys to the basement?\n",
            "Ali: Oh, I have them with me... Sorry, I forgot to out them back...\n",
            "Aline: ...\n",
            "Aline: What time are you coming back?\n",
            "Ali: 7:00\n",
            "Aline: Don't do that again, please...\n",
            "\n",
            "Summary:\n",
            "Aline wonders where Ali left the keys to the basement, and he has them with him. Ali is coming back at 7:00, which Aline isn't happy about. \n",
            "\n",
            "\n",
            "Generated Summary\n",
            "Ali forgot to put the keys to the basement in the basement. He will return to the basement at 7 p.m. on Friday. Aline will be waiting for him at the basement.\n"
          ]
        }
      ],
      "source": [
        "max_length = 48\n",
        "sample = get_random_sample()\n",
        "print(\"Dialogue:\")\n",
        "print(sample[\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(sample[\"summary\"])\n",
        "print(\"\\n\\nGenerated Summary\")\n",
        "pipe_out = pipe(sample[\"dialogue\"], max_length=max_length)\n",
        "print(pipe_out[0][\"summary_text\"].replace(\"<n>\", \"\\n\"))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Dialogue Summarization",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "112f6a8c7922410e8c72c35f4502a5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c15ec4f9e29f4835b085bb0223b5ebfc",
              "IPY_MODEL_da7601058b3d40f6b9cbbbfddaeeaa5c",
              "IPY_MODEL_99b892d921d8408a8d6d795d706a55a0"
            ],
            "layout": "IPY_MODEL_379f5f2448d84d709169c0a516170329"
          }
        },
        "3073778c52f9432492d1f9e446440e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "379f5f2448d84d709169c0a516170329": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a4b53c890b4180ac72b2cffd8f47e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fab5b69a4d47a89c90874da8c39977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538d907a219b42ca845805d65b762b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b892d921d8408a8d6d795d706a55a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52fab5b69a4d47a89c90874da8c39977",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f987516d481b43e78b8661ec5833d913",
            "value": "‚Äá819/819‚Äá[00:00&lt;00:00,‚Äá2028.94‚Äáexamples/s]"
          }
        },
        "c15ec4f9e29f4835b085bb0223b5ebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a4b53c890b4180ac72b2cffd8f47e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_538d907a219b42ca845805d65b762b2f",
            "value": "Map:‚Äá100%"
          }
        },
        "c87ef4c88e4f4048975ffd2edff484e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7601058b3d40f6b9cbbbfddaeeaa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87ef4c88e4f4048975ffd2edff484e6",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3073778c52f9432492d1f9e446440e20",
            "value": 819
          }
        },
        "f987516d481b43e78b8661ec5833d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
